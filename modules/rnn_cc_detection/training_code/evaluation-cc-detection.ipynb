{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook to test the effectiveness of the CC detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 11:10:09.756444: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-21 11:10:09.756511: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-21 11:10:09.758940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-21 11:10:09.772477: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-21 11:10:11.553646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Default values\n",
    "csvfile = '../datasets/all_datasets_raw.tsv'\n",
    "# Less than 5 letters is just too small to know if it is a CC or not. So we set a minimum.\n",
    "min_letters = 5\n",
    "# The max 500 letters is arbitrary but we believe that less than 50 letters should be enough to know if it is a CC\n",
    "max_letters = 500\n",
    "# In case the sequences are too long to load, is better to never load more than some amount from file to memory. A safeguard\n",
    "take_last_num = lambda x: x[: max_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframe from the TSV file\n",
    "df = pd.read_csv(\n",
    "        csvfile,\n",
    "        delimiter=\"|\",\n",
    "        names=[\"note\", \"label\", \"model_id\", \"state\"],\n",
    "        skipinitialspace=True,\n",
    "        converters={\"state\": take_last_num},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset\n",
    "df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "df.drop(axis=1, columns=[\"note\", \"model_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the strings of letters with less than a certain amount\n",
    "indexNames = df[df[\"state\"].str.len() < min_letters].index\n",
    "df.drop(indexNames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the dataframe with the label. The label is 'Normal' for the normal data and 'Malcious' for the malware data\n",
    "df.loc[df.label.str.contains(\"Normal\"), \"label\"] = \"Normal\"\n",
    "df.loc[df.label.str.contains(\"Botnet\"), \"label\"] = \"Malicious\"\n",
    "df.loc[df.label.str.contains(\"Malware\"), \"label\"] = \"Malicious\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2343781/3015528503.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.label = df.label.replace(\"Normal\", 0)\n"
     ]
    }
   ],
   "source": [
    "# Encode the label as an integer. 1 for maliciuos, 0 for benign. \n",
    "df.label = df.label.replace(\"Malicious\", 1)\n",
    "df.label = df.label.replace(\"Normal\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 letters in total. From letter index 0.0 to letter index 49.0.\n"
     ]
    }
   ],
   "source": [
    "# Convert each of the stratosphere letters to an integer as an encoding. There are 50 symbols\n",
    "vocabulary = list(\"abcdefghiABCDEFGHIrstuvwxyzRSTUVWXYZ1234567890,.+*\")\n",
    "int_of_letters = {}\n",
    "for i, letter in enumerate(vocabulary):\n",
    "    int_of_letters[letter] = float(i)\n",
    "print( f\"There are {len(int_of_letters)} letters in total. From letter index {min(int_of_letters.values())} to letter index {max(int_of_letters.values())}.\")\n",
    "vocabulary_size = len(int_of_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the letters in the state to an integer representing it uniquely. We 'encode' them.\n",
    "df[\"state\"] = df[\"state\"].apply(lambda x: [[int_of_letters[i]] for i in x])\n",
    "# So far, only 1 feature per letter\n",
    "features_per_sample = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70    [[44.0], [44.0], [45.0], [17.0], [17.0], [49.0...\n",
       "71    [[36.0], [36.0], [47.0], [27.0], [47.0], [27.0...\n",
       "73             [[44.0], [41.0], [47.0], [14.0], [47.0]]\n",
       "75    [[41.0], [41.0], [47.0], [35.0], [47.0], [26.0...\n",
       "76    [[44.0], [44.0], [47.0], [35.0], [47.0], [26.0...\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the encoding looks like\n",
    "df.state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2228 outtuples\n"
     ]
    }
   ],
   "source": [
    "# Convert the data into the appropriate shape\n",
    "# x_data is a list of lists. The 1st dimension is the outtuple, the second the letter. Each letter is now an int value. shape=(num_outuples, features_per_sample)\n",
    "x_data = df[\"state\"].to_numpy()\n",
    "print(f\"There are {len(x_data)} outtuples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2228 labels\n"
     ]
    }
   ],
   "source": [
    "# y_data is a list of ints that are 0 or 1. One integer per outtupple. shape=(num_outuples, 1)\n",
    "y_data = df[\"label\"].to_numpy()\n",
    "print(f\"There are {len(y_data)} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data type <class 'numpy.ndarray'> of shape (2228,). x_data[0] type is <class 'list'>\n",
      "x_data[0] is [[44.0], [44.0], [45.0], [17.0], [17.0], [49.0], [26.0], [49.0], [45.0], [35.0], [45.0], [17.0]]\n"
     ]
    }
   ],
   "source": [
    "# Here x_data is a array of lists [[]]\n",
    "print(f\"x_data type {type(x_data)} of shape {x_data.shape}. x_data[0] type is {type(x_data[0])}\")\n",
    "print(f\"x_data[0] is {x_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max len of the letters in all outtuples is: 500\n"
     ]
    }
   ],
   "source": [
    "# Search the sample with max len in the training. It should be already cuted by the csv_read function to a max. Here we just check\n",
    "max_length_of_outtupple = max([len(sublist) for sublist in df.state.to_list()])\n",
    "print(f\"The max len of the letters in all outtuples is: {max_length_of_outtupple}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_x_data is of type <class 'numpy.ndarray'>, of shape (2228, 500, 1). padded_x_data[0] type is <class 'numpy.ndarray'>. Shape of second list is (500, 1)\n"
     ]
    }
   ],
   "source": [
    "# Padding.\n",
    "# Since not all outtuples have the same amount of letters, we need to add padding at the end\n",
    "# Transforms the list to a 2D Numpy array of shape (num_samples, num_timesteps)\n",
    "# num_timesteps is either the maxlen argument if provided, or the length of the longest sequence otherwise.\n",
    "# Sequences that are shorter than num_timesteps are padded with value at the end.\n",
    "# padding: 'pre' or 'post': pad either before or after each sequence.\n",
    "# truncating: 'pre' or 'post': remove values from sequences larger than maxlen, either at the beginning or at the end of the sequences.\n",
    "\n",
    "# If the input are integers\n",
    "padded_x_data = pad_sequences(\n",
    "    x_data, maxlen=max_length_of_outtupple, padding=\"post\"\n",
    ")\n",
    "print(\n",
    "        f\"padded_x_data is of type {type(padded_x_data)}, of shape {padded_x_data.shape}. padded_x_data[0] type is {type(padded_x_data[0])}. Shape of second list is {padded_x_data[0].shape}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in training/evaluation and testing\n",
    "x_data = padded_x_data\n",
    "y_data = y_data\n",
    "\n",
    "X_traineval, X_test, y_traineval, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have as shape: Num of samples: 1782, Num of letters per sample (timesteps): 500, each letter has 1 values. The input shape is (1782, 1)\n"
     ]
    }
   ],
   "source": [
    "num_outtuples = X_traineval.shape[0]  # number_of_outtuples in general\n",
    "\n",
    "# In the case of hot-encoding, the amount of features per letter per sample, is 50, which is the vocabulary size\n",
    "# features_per_sample = vocabulary_size # amount of positions of the hot encoding (50 letters, so 50)\n",
    "# print(f'We have as input shape: {num_outtuples}, {max_length_of_outtupple}, {features_per_sample}')\n",
    "# input_shape = (num_outtuples, features_per_sample)\n",
    "\n",
    "# In the case of not using hot-encoding, the amount of features per sample is 1, because we only have one value\n",
    "# The amount of time steps is the amount of letters, since one letter is one time step, which is the amount of letters max, which 500\n",
    "input_shape = (num_outtuples, features_per_sample)\n",
    "print(\n",
    "    f\"We have as shape: Num of samples: {num_outtuples}, Num of letters per sample (timesteps): {max_length_of_outtupple}, each letter has {features_per_sample} values. The input shape is {input_shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model being explored. Used for file name creation.\n",
    "model_trained = 'v1.2'\n",
    "\n",
    "# Get current date\n",
    "model_train_date = datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Optimize hyperparameters with optuna and find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test optuna\n",
    "import optuna\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function\n",
    "def objective(trial):\n",
    "    # Open a log file\n",
    "\n",
    "    # Define ranges of hyperparameters to optimize\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    momentum_rate = trial.suggest_float(\"momentum_rate\", 0.0, 0.1)\n",
    "    embed_dim = trial.suggest_int(\"embedded_dim\", 8, 64)\n",
    "\n",
    "    log = f'Trial: {trial}. Trying lr:{learning_rate}, drop:{dropout_rate}, embed:{embed_dim}'\n",
    "    print(log)\n",
    "    \n",
    "    # Load dataset\n",
    "    X_traineval, X_test, y_traineval, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)    \n",
    "    \n",
    "    # Create the model of RNN\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Embedding(vocabulary_size, embed_dim, mask_zero=True))\n",
    "    # GRU is the main RNN layer, inputs: A 3D tensor, with shape [batch, timesteps, feature]\n",
    "    model.add(\n",
    "        layers.Bidirectional(\n",
    "            layers.GRU(32, return_sequences=False), merge_mode=\"concat\"\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    # Fully connected layer with 1 neuron output\n",
    "    # Final output value between 0 and 1 as probability\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_traineval, y_traineval, validation_data=(X_traineval, y_traineval), epochs=30, batch_size=100, verbose=1)\n",
    "    \n",
    "    # Evaluate model\n",
    "    val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    log = f'\\tVal_acc: {val_acc}. Val_loss: {val_loss}'\n",
    "    print(log)\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 19:07:55,364] A new study created in memory with name: no-name-e890ec9d-9c47-428f-bd73-d7e886fb43cf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 23s 675ms/step - loss: 0.6246 - accuracy: 0.6857 - val_loss: 0.4951 - val_accuracy: 0.7116\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 8s 457ms/step - loss: 0.3902 - accuracy: 0.8260 - val_loss: 0.2871 - val_accuracy: 0.9040\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.2788 - accuracy: 0.8906 - val_loss: 0.2284 - val_accuracy: 0.8962\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.2291 - accuracy: 0.8984 - val_loss: 0.2069 - val_accuracy: 0.9068\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 8s 477ms/step - loss: 0.2148 - accuracy: 0.9052 - val_loss: 0.1971 - val_accuracy: 0.9052\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 8s 455ms/step - loss: 0.2069 - accuracy: 0.9074 - val_loss: 0.1874 - val_accuracy: 0.9198\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.1986 - accuracy: 0.9158 - val_loss: 0.1761 - val_accuracy: 0.9248\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.1846 - accuracy: 0.9265 - val_loss: 0.1721 - val_accuracy: 0.9209\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.1764 - accuracy: 0.9254 - val_loss: 0.1663 - val_accuracy: 0.9276\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 8s 448ms/step - loss: 0.1746 - accuracy: 0.9259 - val_loss: 0.1558 - val_accuracy: 0.9343\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.1732 - accuracy: 0.9287 - val_loss: 0.1512 - val_accuracy: 0.9383\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.1647 - accuracy: 0.9383 - val_loss: 0.1450 - val_accuracy: 0.9416\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.1556 - accuracy: 0.9422 - val_loss: 0.1455 - val_accuracy: 0.9383\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.1521 - accuracy: 0.9383 - val_loss: 0.1283 - val_accuracy: 0.9501\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.1501 - accuracy: 0.9444 - val_loss: 0.1239 - val_accuracy: 0.9484\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.1352 - accuracy: 0.9484 - val_loss: 0.1177 - val_accuracy: 0.9557\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.1272 - accuracy: 0.9517 - val_loss: 0.1113 - val_accuracy: 0.9574\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.1314 - accuracy: 0.9506 - val_loss: 0.1551 - val_accuracy: 0.9444\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 8s 448ms/step - loss: 0.1639 - accuracy: 0.9349 - val_loss: 0.1293 - val_accuracy: 0.9478\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.1367 - accuracy: 0.9444 - val_loss: 0.1133 - val_accuracy: 0.9529\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.1251 - accuracy: 0.9478 - val_loss: 0.1078 - val_accuracy: 0.9568\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.1164 - accuracy: 0.9456 - val_loss: 0.1014 - val_accuracy: 0.9585\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.1101 - accuracy: 0.9551 - val_loss: 0.0968 - val_accuracy: 0.9624\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 8s 454ms/step - loss: 0.1056 - accuracy: 0.9562 - val_loss: 0.0947 - val_accuracy: 0.9624\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.1073 - accuracy: 0.9579 - val_loss: 0.0932 - val_accuracy: 0.9635\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 8s 442ms/step - loss: 0.1011 - accuracy: 0.9630 - val_loss: 0.0903 - val_accuracy: 0.9663\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.0995 - accuracy: 0.9596 - val_loss: 0.0874 - val_accuracy: 0.9675\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.1002 - accuracy: 0.9630 - val_loss: 0.0861 - val_accuracy: 0.9669\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.0953 - accuracy: 0.9669 - val_loss: 0.0847 - val_accuracy: 0.9658\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.0953 - accuracy: 0.9574 - val_loss: 0.0812 - val_accuracy: 0.9691\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 9s 489ms/step - loss: 0.0895 - accuracy: 0.9686 - val_loss: 0.0787 - val_accuracy: 0.9680\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0907 - accuracy: 0.9630 - val_loss: 0.0790 - val_accuracy: 0.9686\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 8s 440ms/step - loss: 0.0968 - accuracy: 0.9613 - val_loss: 0.0788 - val_accuracy: 0.9691\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0986 - accuracy: 0.9618 - val_loss: 0.0852 - val_accuracy: 0.9663\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.0947 - accuracy: 0.9646 - val_loss: 0.0781 - val_accuracy: 0.9697\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.0966 - accuracy: 0.9596 - val_loss: 0.0996 - val_accuracy: 0.9652\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 8s 448ms/step - loss: 0.1059 - accuracy: 0.9551 - val_loss: 0.0870 - val_accuracy: 0.9641\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 8s 461ms/step - loss: 0.0912 - accuracy: 0.9630 - val_loss: 0.0787 - val_accuracy: 0.9703\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 8s 451ms/step - loss: 0.0941 - accuracy: 0.9624 - val_loss: 0.0784 - val_accuracy: 0.9719\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.0814 - accuracy: 0.9708 - val_loss: 0.0699 - val_accuracy: 0.9719\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0709 - accuracy: 0.9708 - val_loss: 0.0817 - val_accuracy: 0.9652\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 8s 455ms/step - loss: 0.0857 - accuracy: 0.9680 - val_loss: 0.0671 - val_accuracy: 0.9731\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 8s 456ms/step - loss: 0.0760 - accuracy: 0.9675 - val_loss: 0.0678 - val_accuracy: 0.9736\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0832 - accuracy: 0.9675 - val_loss: 0.0729 - val_accuracy: 0.9708\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.0824 - accuracy: 0.9652 - val_loss: 0.0747 - val_accuracy: 0.9714\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 8s 458ms/step - loss: 0.0783 - accuracy: 0.9686 - val_loss: 0.0701 - val_accuracy: 0.9703\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0759 - accuracy: 0.9686 - val_loss: 0.0684 - val_accuracy: 0.9708\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0793 - accuracy: 0.9675 - val_loss: 0.0765 - val_accuracy: 0.9691\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0753 - accuracy: 0.9697 - val_loss: 0.0648 - val_accuracy: 0.9725\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0815 - accuracy: 0.9652 - val_loss: 0.0655 - val_accuracy: 0.9736\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.0763 - accuracy: 0.9725 - val_loss: 0.0703 - val_accuracy: 0.9714\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0739 - accuracy: 0.9703 - val_loss: 0.0601 - val_accuracy: 0.9742\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0706 - accuracy: 0.9725 - val_loss: 0.0584 - val_accuracy: 0.9764\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.0657 - accuracy: 0.9759 - val_loss: 0.0562 - val_accuracy: 0.9776\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.0720 - accuracy: 0.9708 - val_loss: 0.0712 - val_accuracy: 0.9714\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.0818 - accuracy: 0.9669 - val_loss: 0.0648 - val_accuracy: 0.9759\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0700 - accuracy: 0.9719 - val_loss: 0.0593 - val_accuracy: 0.9725\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.0652 - accuracy: 0.9759 - val_loss: 0.0561 - val_accuracy: 0.9776\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.0615 - accuracy: 0.9764 - val_loss: 0.0539 - val_accuracy: 0.9776\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0609 - accuracy: 0.9759 - val_loss: 0.0519 - val_accuracy: 0.9798\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 8s 452ms/step - loss: 0.0608 - accuracy: 0.9747 - val_loss: 0.0527 - val_accuracy: 0.9787\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0603 - accuracy: 0.9759 - val_loss: 0.0501 - val_accuracy: 0.9798\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 8s 438ms/step - loss: 0.0586 - accuracy: 0.9759 - val_loss: 0.0514 - val_accuracy: 0.9787\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.0564 - accuracy: 0.9759 - val_loss: 0.0469 - val_accuracy: 0.9820\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.0602 - accuracy: 0.9781 - val_loss: 0.0483 - val_accuracy: 0.9832\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.0577 - accuracy: 0.9798 - val_loss: 0.0567 - val_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.0603 - accuracy: 0.9731 - val_loss: 0.0502 - val_accuracy: 0.9792\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 8s 448ms/step - loss: 0.0559 - accuracy: 0.9776 - val_loss: 0.0514 - val_accuracy: 0.9764\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0521 - accuracy: 0.9792 - val_loss: 0.0467 - val_accuracy: 0.9804\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0519 - accuracy: 0.9781 - val_loss: 0.0467 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 8s 452ms/step - loss: 0.0557 - accuracy: 0.9776 - val_loss: 0.0521 - val_accuracy: 0.9798\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.0880 - accuracy: 0.9703 - val_loss: 0.0901 - val_accuracy: 0.9596\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.1039 - accuracy: 0.9568 - val_loss: 0.0763 - val_accuracy: 0.9630\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 8s 444ms/step - loss: 0.1932 - accuracy: 0.9495 - val_loss: 0.1663 - val_accuracy: 0.9343\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.1560 - accuracy: 0.9304 - val_loss: 0.1134 - val_accuracy: 0.9512\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 8s 451ms/step - loss: 0.1162 - accuracy: 0.9489 - val_loss: 0.0976 - val_accuracy: 0.9590\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 8s 443ms/step - loss: 0.0925 - accuracy: 0.9675 - val_loss: 0.0823 - val_accuracy: 0.9641\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.0893 - accuracy: 0.9602 - val_loss: 0.0736 - val_accuracy: 0.9663\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0829 - accuracy: 0.9663 - val_loss: 0.0664 - val_accuracy: 0.9731\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.0760 - accuracy: 0.9686 - val_loss: 0.0634 - val_accuracy: 0.9719\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.0716 - accuracy: 0.9697 - val_loss: 0.0580 - val_accuracy: 0.9776\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0687 - accuracy: 0.9742 - val_loss: 0.0561 - val_accuracy: 0.9747\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.0602 - accuracy: 0.9759 - val_loss: 0.0517 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 8s 453ms/step - loss: 0.0589 - accuracy: 0.9770 - val_loss: 0.0498 - val_accuracy: 0.9804\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0543 - accuracy: 0.9792 - val_loss: 0.0479 - val_accuracy: 0.9820\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0510 - accuracy: 0.9770 - val_loss: 0.0473 - val_accuracy: 0.9804\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 8s 448ms/step - loss: 0.0564 - accuracy: 0.9781 - val_loss: 0.0449 - val_accuracy: 0.9820\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 8s 452ms/step - loss: 0.0523 - accuracy: 0.9770 - val_loss: 0.0437 - val_accuracy: 0.9820\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 8s 445ms/step - loss: 0.0510 - accuracy: 0.9798 - val_loss: 0.0427 - val_accuracy: 0.9820\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.0504 - accuracy: 0.9787 - val_loss: 0.0410 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 9s 487ms/step - loss: 0.0475 - accuracy: 0.9787 - val_loss: 0.0392 - val_accuracy: 0.9832\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.0454 - accuracy: 0.9804 - val_loss: 0.0384 - val_accuracy: 0.9843\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 8s 450ms/step - loss: 0.0397 - accuracy: 0.9843 - val_loss: 0.0368 - val_accuracy: 0.9837\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 8s 441ms/step - loss: 0.0416 - accuracy: 0.9837 - val_loss: 0.0384 - val_accuracy: 0.9820\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.0472 - accuracy: 0.9787 - val_loss: 0.0368 - val_accuracy: 0.9837\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 8s 454ms/step - loss: 0.0439 - accuracy: 0.9826 - val_loss: 0.0358 - val_accuracy: 0.9826\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 8s 449ms/step - loss: 0.0432 - accuracy: 0.9798 - val_loss: 0.0342 - val_accuracy: 0.9860\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 8s 446ms/step - loss: 0.0415 - accuracy: 0.9809 - val_loss: 0.0352 - val_accuracy: 0.9832\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 9s 495ms/step - loss: 0.0396 - accuracy: 0.9832 - val_loss: 0.0319 - val_accuracy: 0.9854\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 8s 447ms/step - loss: 0.0369 - accuracy: 0.9843 - val_loss: 0.0313 - val_accuracy: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 19:21:31,901] Trial 0 finished with value: 0.9484304785728455 and parameters: {'learning_rate': 0.0015065274434556085, 'dropout_rate': 0.4673636470221263, 'momentum_rate': 0.04051167539159986, 'embedded_dim': 50}. Best is trial 0 with value: 0.9484304785728455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 2/18 [==>...........................] - ETA: 5s - loss: 0.6967 - accuracy: 0.4550  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-04-20 19:21:48,433] Trial 1 failed with parameters: {'learning_rate': 0.001686188041159955, 'dropout_rate': 0.36320637813046414, 'momentum_rate': 0.09289876520278277, 'embedded_dim': 57} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_2258671/388873977.py\", line 33, in objective\n",
      "    model.fit(X_traineval, y_traineval, validation_data=(X_traineval, y_traineval), epochs=100, batch_size=100, verbose=1)\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 868, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
      "    outputs = execute.execute(\n",
      "  File \"/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "[W 2024-04-20 19:21:48,435] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[135], line 3\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set up Optuna study\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get best hyperparameters\u001b[39;00m\n",
      "\u001b[1;32m      6\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n",
      "\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n",
      "\u001b[1;32m    360\u001b[0m \n",
      "\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n",
      "\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n",
      "\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n",
      "\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n",
      "\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n",
      "\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n",
      "\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n",
      "\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n",
      "\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n",
      "\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n",
      "\u001b[1;32m    246\u001b[0m ):\n",
      "\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n",
      "\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n",
      "\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n",
      "\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n",
      "\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "\n",
      "Cell \u001b[0;32mIn[134], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n",
      "\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m),\n",
      "\u001b[1;32m     29\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n",
      "\u001b[1;32m     30\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n",
      "\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_traineval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_traineval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_traineval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_traineval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n",
      "\u001b[1;32m     36\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n",
      "\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n",
      "\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n",
      "\u001b[1;32m   1805\u001b[0m ):\n",
      "\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n",
      "\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n",
      "\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n",
      "\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n",
      "\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n",
      "\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n",
      "\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n",
      "\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n",
      "\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n",
      "\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n",
      "\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n",
      "\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n",
      "\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n",
      "\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n",
      "\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n",
      "\u001b[1;32m   1325\u001b[0m     args,\n",
      "\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n",
      "\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n",
      "\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n",
      "\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n",
      "\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n",
      "\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n",
      "\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n",
      "\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n",
      "\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n",
      "\u001b[1;32m    261\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n",
      "\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n",
      "\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n",
      "\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n",
      "\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n",
      "\u001b[1;32m   1501\u001b[0m   )\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/slips/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n",
      "\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "\n",
    "logfile = open('notebook.log', 'w+')\n",
    "log = f'Best hyperparameters: {best_params}'\n",
    "print(log)\n",
    "logfile.write(log)\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters: {'learning_rate': 0.001896219962316226, 'dropout_rate': 0.3405832906149749, 'momentum_rate': 0.05593281020818976, 'embedded_dim': 64}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. This is to manual train the model if you know the hyperparameters you want. To find the best parameters see next section optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model v1\n",
    "# Hyperparameters\n",
    "vocabulary_size = vocabulary_size\n",
    "embed_dim = 64\n",
    "\n",
    "# Create the model of RNN\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Embedding(vocabulary_size, embed_dim, mask_zero=True))\n",
    "# GRU is the main RNN layer, inputs: A 3D tensor, with shape [batch, timesteps, feature]\n",
    "model.add(\n",
    "    layers.Bidirectional(\n",
    "        layers.GRU(32, return_sequences=False), merge_mode=\"concat\"\n",
    "    )\n",
    ")\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.34))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "# Fully connected layer with 1 neuron output\n",
    "# Final output value between 0 and 1 as probability\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001896219962316226, momentum=0.05),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "17/17 [==============================] - 21s 585ms/step - loss: 0.4964 - accuracy: 0.8384 - val_loss: 0.2668 - val_accuracy: 0.9162\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.2554 - accuracy: 0.9089 - val_loss: 0.2380 - val_accuracy: 0.8939\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.2285 - accuracy: 0.9108 - val_loss: 0.2096 - val_accuracy: 0.9274\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 6s 360ms/step - loss: 0.2185 - accuracy: 0.9095 - val_loss: 0.2219 - val_accuracy: 0.8827\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.2039 - accuracy: 0.9183 - val_loss: 0.2053 - val_accuracy: 0.9050\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.1972 - accuracy: 0.9164 - val_loss: 0.2043 - val_accuracy: 0.9106\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.1812 - accuracy: 0.9264 - val_loss: 0.1978 - val_accuracy: 0.9274\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.1776 - accuracy: 0.9283 - val_loss: 0.2261 - val_accuracy: 0.9050\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.1686 - accuracy: 0.9308 - val_loss: 0.1911 - val_accuracy: 0.9385\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.1614 - accuracy: 0.9351 - val_loss: 0.2161 - val_accuracy: 0.9330\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 6s 356ms/step - loss: 0.1608 - accuracy: 0.9345 - val_loss: 0.1800 - val_accuracy: 0.9385\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.1547 - accuracy: 0.9376 - val_loss: 0.1845 - val_accuracy: 0.9330\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.1512 - accuracy: 0.9426 - val_loss: 0.2039 - val_accuracy: 0.9218\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.1530 - accuracy: 0.9345 - val_loss: 0.1831 - val_accuracy: 0.9330\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.1464 - accuracy: 0.9401 - val_loss: 0.1653 - val_accuracy: 0.9385\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.1407 - accuracy: 0.9420 - val_loss: 0.2685 - val_accuracy: 0.9162\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.1423 - accuracy: 0.9445 - val_loss: 0.1649 - val_accuracy: 0.9218\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.1379 - accuracy: 0.9513 - val_loss: 0.1768 - val_accuracy: 0.9385\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.1333 - accuracy: 0.9451 - val_loss: 0.1758 - val_accuracy: 0.9330\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.1270 - accuracy: 0.9513 - val_loss: 0.1763 - val_accuracy: 0.9441\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.1270 - accuracy: 0.9488 - val_loss: 0.1870 - val_accuracy: 0.9330\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.1249 - accuracy: 0.9482 - val_loss: 0.1862 - val_accuracy: 0.9330\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.1243 - accuracy: 0.9507 - val_loss: 0.1714 - val_accuracy: 0.9274\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.1291 - accuracy: 0.9501 - val_loss: 0.1894 - val_accuracy: 0.9274\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.1150 - accuracy: 0.9538 - val_loss: 0.1697 - val_accuracy: 0.9385\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.1148 - accuracy: 0.9545 - val_loss: 0.1679 - val_accuracy: 0.9218\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 6s 359ms/step - loss: 0.1210 - accuracy: 0.9520 - val_loss: 0.2092 - val_accuracy: 0.9050\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.1273 - accuracy: 0.9432 - val_loss: 0.1580 - val_accuracy: 0.9385\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.1147 - accuracy: 0.9545 - val_loss: 0.1642 - val_accuracy: 0.9385\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.1205 - accuracy: 0.9507 - val_loss: 0.1572 - val_accuracy: 0.9441\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.1220 - accuracy: 0.9526 - val_loss: 0.1802 - val_accuracy: 0.9330\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.1089 - accuracy: 0.9551 - val_loss: 0.2239 - val_accuracy: 0.9218\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.1085 - accuracy: 0.9551 - val_loss: 0.2476 - val_accuracy: 0.9218\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.1145 - accuracy: 0.9582 - val_loss: 0.1590 - val_accuracy: 0.9441\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.1121 - accuracy: 0.9507 - val_loss: 0.2021 - val_accuracy: 0.9162\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.1050 - accuracy: 0.9557 - val_loss: 0.1728 - val_accuracy: 0.9330\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.1036 - accuracy: 0.9545 - val_loss: 0.2008 - val_accuracy: 0.9441\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.1091 - accuracy: 0.9595 - val_loss: 0.2297 - val_accuracy: 0.9218\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.1085 - accuracy: 0.9551 - val_loss: 0.1831 - val_accuracy: 0.9218\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.1049 - accuracy: 0.9576 - val_loss: 0.2003 - val_accuracy: 0.9274\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.1129 - accuracy: 0.9557 - val_loss: 0.2153 - val_accuracy: 0.9330\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0955 - accuracy: 0.9619 - val_loss: 0.2188 - val_accuracy: 0.9330\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0988 - accuracy: 0.9651 - val_loss: 0.2823 - val_accuracy: 0.9441\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0959 - accuracy: 0.9644 - val_loss: 0.2131 - val_accuracy: 0.9441\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0932 - accuracy: 0.9607 - val_loss: 0.2339 - val_accuracy: 0.9274\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.1021 - accuracy: 0.9595 - val_loss: 0.2024 - val_accuracy: 0.9330\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0980 - accuracy: 0.9551 - val_loss: 0.2913 - val_accuracy: 0.9050\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.1064 - accuracy: 0.9563 - val_loss: 0.2457 - val_accuracy: 0.9274\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0909 - accuracy: 0.9626 - val_loss: 0.2735 - val_accuracy: 0.9330\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0893 - accuracy: 0.9626 - val_loss: 0.1986 - val_accuracy: 0.9385\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0885 - accuracy: 0.9607 - val_loss: 0.2494 - val_accuracy: 0.9274\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0793 - accuracy: 0.9676 - val_loss: 0.2508 - val_accuracy: 0.9330\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0890 - accuracy: 0.9644 - val_loss: 0.2486 - val_accuracy: 0.9385\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0913 - accuracy: 0.9626 - val_loss: 0.2207 - val_accuracy: 0.9218\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0864 - accuracy: 0.9626 - val_loss: 0.2713 - val_accuracy: 0.9274\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0847 - accuracy: 0.9651 - val_loss: 0.2675 - val_accuracy: 0.9274\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0819 - accuracy: 0.9682 - val_loss: 0.2220 - val_accuracy: 0.9162\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 6s 358ms/step - loss: 0.0838 - accuracy: 0.9644 - val_loss: 0.2927 - val_accuracy: 0.9218\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0768 - accuracy: 0.9663 - val_loss: 0.2337 - val_accuracy: 0.9274\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 6s 356ms/step - loss: 0.0890 - accuracy: 0.9601 - val_loss: 0.2879 - val_accuracy: 0.9106\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0823 - accuracy: 0.9632 - val_loss: 0.2763 - val_accuracy: 0.9385\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0790 - accuracy: 0.9619 - val_loss: 0.2432 - val_accuracy: 0.9274\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0865 - accuracy: 0.9626 - val_loss: 0.2560 - val_accuracy: 0.9330\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0926 - accuracy: 0.9701 - val_loss: 0.2577 - val_accuracy: 0.9330\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0836 - accuracy: 0.9644 - val_loss: 0.2817 - val_accuracy: 0.9441\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0770 - accuracy: 0.9726 - val_loss: 0.2639 - val_accuracy: 0.9274\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0812 - accuracy: 0.9719 - val_loss: 0.2920 - val_accuracy: 0.9385\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0804 - accuracy: 0.9676 - val_loss: 0.3305 - val_accuracy: 0.9274\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0885 - accuracy: 0.9638 - val_loss: 0.3110 - val_accuracy: 0.9441\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0780 - accuracy: 0.9644 - val_loss: 0.2381 - val_accuracy: 0.9274\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 6s 360ms/step - loss: 0.0815 - accuracy: 0.9688 - val_loss: 0.2744 - val_accuracy: 0.9218\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0669 - accuracy: 0.9682 - val_loss: 0.3062 - val_accuracy: 0.9385\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0726 - accuracy: 0.9694 - val_loss: 0.2907 - val_accuracy: 0.9330\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0640 - accuracy: 0.9707 - val_loss: 0.2672 - val_accuracy: 0.9385\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0742 - accuracy: 0.9688 - val_loss: 0.3073 - val_accuracy: 0.9441\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0640 - accuracy: 0.9750 - val_loss: 0.2833 - val_accuracy: 0.9218\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0629 - accuracy: 0.9750 - val_loss: 0.2958 - val_accuracy: 0.9330\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0706 - accuracy: 0.9688 - val_loss: 0.2468 - val_accuracy: 0.9274\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0669 - accuracy: 0.9744 - val_loss: 0.2901 - val_accuracy: 0.9274\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0684 - accuracy: 0.9732 - val_loss: 0.2490 - val_accuracy: 0.9218\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0615 - accuracy: 0.9788 - val_loss: 0.3073 - val_accuracy: 0.9274\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0640 - accuracy: 0.9769 - val_loss: 0.3820 - val_accuracy: 0.9218\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0623 - accuracy: 0.9726 - val_loss: 0.2755 - val_accuracy: 0.9385\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0693 - accuracy: 0.9707 - val_loss: 0.3096 - val_accuracy: 0.9218\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0619 - accuracy: 0.9719 - val_loss: 0.3392 - val_accuracy: 0.9330\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0603 - accuracy: 0.9750 - val_loss: 0.3439 - val_accuracy: 0.9330\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0678 - accuracy: 0.9707 - val_loss: 0.3391 - val_accuracy: 0.9274\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0594 - accuracy: 0.9775 - val_loss: 0.3535 - val_accuracy: 0.9441\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0732 - accuracy: 0.9738 - val_loss: 0.3168 - val_accuracy: 0.9330\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0592 - accuracy: 0.9750 - val_loss: 0.3182 - val_accuracy: 0.9385\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0512 - accuracy: 0.9775 - val_loss: 0.3475 - val_accuracy: 0.9330\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0598 - accuracy: 0.9707 - val_loss: 0.3434 - val_accuracy: 0.9385\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0570 - accuracy: 0.9732 - val_loss: 0.3328 - val_accuracy: 0.9385\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0543 - accuracy: 0.9769 - val_loss: 0.3249 - val_accuracy: 0.9218\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0516 - accuracy: 0.9813 - val_loss: 0.3087 - val_accuracy: 0.9274\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0514 - accuracy: 0.9769 - val_loss: 0.3419 - val_accuracy: 0.9274\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.3180 - val_accuracy: 0.9330\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0519 - accuracy: 0.9763 - val_loss: 0.3539 - val_accuracy: 0.9385\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0442 - accuracy: 0.9838 - val_loss: 0.3814 - val_accuracy: 0.9274\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0534 - accuracy: 0.9769 - val_loss: 0.3720 - val_accuracy: 0.9385\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0456 - accuracy: 0.9813 - val_loss: 0.3230 - val_accuracy: 0.9274\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0586 - accuracy: 0.9838 - val_loss: 0.3324 - val_accuracy: 0.9330\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0480 - accuracy: 0.9800 - val_loss: 0.3772 - val_accuracy: 0.9330\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0396 - accuracy: 0.9807 - val_loss: 0.3701 - val_accuracy: 0.9330\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0419 - accuracy: 0.9850 - val_loss: 0.4024 - val_accuracy: 0.9274\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0410 - accuracy: 0.9838 - val_loss: 0.3945 - val_accuracy: 0.9330\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0366 - accuracy: 0.9838 - val_loss: 0.3424 - val_accuracy: 0.9106\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0591 - accuracy: 0.9788 - val_loss: 0.3504 - val_accuracy: 0.9274\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0336 - accuracy: 0.9869 - val_loss: 0.3487 - val_accuracy: 0.9330\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0344 - accuracy: 0.9857 - val_loss: 0.3715 - val_accuracy: 0.9274\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0528 - accuracy: 0.9850 - val_loss: 0.4086 - val_accuracy: 0.9218\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.3494 - val_accuracy: 0.9274\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0420 - accuracy: 0.9844 - val_loss: 0.3969 - val_accuracy: 0.9274\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0366 - accuracy: 0.9838 - val_loss: 0.3839 - val_accuracy: 0.9385\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0500 - accuracy: 0.9838 - val_loss: 0.3645 - val_accuracy: 0.9274\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0303 - accuracy: 0.9875 - val_loss: 0.3717 - val_accuracy: 0.9274\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 6s 341ms/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 0.3903 - val_accuracy: 0.9274\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0521 - accuracy: 0.9800 - val_loss: 0.4111 - val_accuracy: 0.9274\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 0.4315 - val_accuracy: 0.9218\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0354 - accuracy: 0.9838 - val_loss: 0.4575 - val_accuracy: 0.9218\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.4347 - val_accuracy: 0.9162\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0355 - accuracy: 0.9832 - val_loss: 0.4050 - val_accuracy: 0.9330\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0462 - accuracy: 0.9881 - val_loss: 0.4931 - val_accuracy: 0.9218\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0337 - accuracy: 0.9857 - val_loss: 0.4480 - val_accuracy: 0.9385\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0390 - accuracy: 0.9844 - val_loss: 0.4226 - val_accuracy: 0.9218\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0346 - accuracy: 0.9875 - val_loss: 0.4881 - val_accuracy: 0.9330\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.4285 - val_accuracy: 0.9218\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0331 - accuracy: 0.9850 - val_loss: 0.4272 - val_accuracy: 0.9330\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0336 - accuracy: 0.9869 - val_loss: 0.3970 - val_accuracy: 0.9218\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0272 - accuracy: 0.9894 - val_loss: 0.4654 - val_accuracy: 0.9274\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 0.3778 - val_accuracy: 0.9385\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0345 - accuracy: 0.9844 - val_loss: 0.4324 - val_accuracy: 0.9274\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0282 - accuracy: 0.9881 - val_loss: 0.4941 - val_accuracy: 0.9106\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0248 - accuracy: 0.9894 - val_loss: 0.4271 - val_accuracy: 0.9218\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 6s 342ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.4482 - val_accuracy: 0.9274\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0332 - accuracy: 0.9863 - val_loss: 0.4432 - val_accuracy: 0.9274\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.4712 - val_accuracy: 0.9218\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0312 - accuracy: 0.9869 - val_loss: 0.4468 - val_accuracy: 0.9218\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.5035 - val_accuracy: 0.9106\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0290 - accuracy: 0.9875 - val_loss: 0.5255 - val_accuracy: 0.9106\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0500 - accuracy: 0.9888 - val_loss: 0.5664 - val_accuracy: 0.9162\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0298 - accuracy: 0.9875 - val_loss: 0.6438 - val_accuracy: 0.9218\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0302 - accuracy: 0.9857 - val_loss: 0.5144 - val_accuracy: 0.9162\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0220 - accuracy: 0.9894 - val_loss: 0.4966 - val_accuracy: 0.9274\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 0.5058 - val_accuracy: 0.9218\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0209 - accuracy: 0.9900 - val_loss: 0.5764 - val_accuracy: 0.9218\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0266 - accuracy: 0.9888 - val_loss: 0.4790 - val_accuracy: 0.9218\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 0.4736 - val_accuracy: 0.9162\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 0.5276 - val_accuracy: 0.9274\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0186 - accuracy: 0.9919 - val_loss: 0.6192 - val_accuracy: 0.9274\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0328 - accuracy: 0.9888 - val_loss: 0.5472 - val_accuracy: 0.9274\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 6s 356ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.6262 - val_accuracy: 0.9162\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0203 - accuracy: 0.9894 - val_loss: 0.5570 - val_accuracy: 0.9106\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0143 - accuracy: 0.9938 - val_loss: 0.5385 - val_accuracy: 0.9162\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0243 - accuracy: 0.9906 - val_loss: 0.5290 - val_accuracy: 0.9162\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0259 - accuracy: 0.9888 - val_loss: 0.5605 - val_accuracy: 0.9162\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0208 - accuracy: 0.9906 - val_loss: 0.5831 - val_accuracy: 0.9106\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0204 - accuracy: 0.9900 - val_loss: 0.6251 - val_accuracy: 0.9106\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0292 - accuracy: 0.9906 - val_loss: 0.5709 - val_accuracy: 0.9274\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.5871 - val_accuracy: 0.9106\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.4807 - val_accuracy: 0.9274\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.5238 - val_accuracy: 0.9274\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0307 - accuracy: 0.9863 - val_loss: 0.5305 - val_accuracy: 0.9162\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0119 - accuracy: 0.9944 - val_loss: 0.5442 - val_accuracy: 0.9218\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.5712 - val_accuracy: 0.9162\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 0.5830 - val_accuracy: 0.9162\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0313 - accuracy: 0.9913 - val_loss: 0.5714 - val_accuracy: 0.9162\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0144 - accuracy: 0.9919 - val_loss: 0.5612 - val_accuracy: 0.9162\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.5497 - val_accuracy: 0.9162\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 0.0207 - accuracy: 0.9906 - val_loss: 0.5492 - val_accuracy: 0.9274\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.5596 - val_accuracy: 0.9162\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.5260 - val_accuracy: 0.9441\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.5189 - val_accuracy: 0.9218\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0145 - accuracy: 0.9938 - val_loss: 0.4993 - val_accuracy: 0.9162\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.6351 - val_accuracy: 0.9274\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 0.5186 - val_accuracy: 0.9385\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.5089 - val_accuracy: 0.9274\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0169 - accuracy: 0.9906 - val_loss: 0.5397 - val_accuracy: 0.9218\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.5577 - val_accuracy: 0.9385\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.5628 - val_accuracy: 0.9162\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0155 - accuracy: 0.9919 - val_loss: 0.5707 - val_accuracy: 0.9106\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0143 - accuracy: 0.9944 - val_loss: 0.4747 - val_accuracy: 0.9218\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0347 - accuracy: 0.9894 - val_loss: 0.5301 - val_accuracy: 0.9218\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0134 - accuracy: 0.9931 - val_loss: 0.5976 - val_accuracy: 0.9218\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0135 - accuracy: 0.9938 - val_loss: 0.5648 - val_accuracy: 0.9218\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0162 - accuracy: 0.9925 - val_loss: 0.6028 - val_accuracy: 0.9162\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0089 - accuracy: 0.9956 - val_loss: 0.5914 - val_accuracy: 0.9162\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0161 - accuracy: 0.9931 - val_loss: 0.6128 - val_accuracy: 0.9218\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 0.5951 - val_accuracy: 0.9162\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0216 - accuracy: 0.9913 - val_loss: 0.5842 - val_accuracy: 0.9218\n",
      "Epoch 191/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0109 - accuracy: 0.9950 - val_loss: 0.5855 - val_accuracy: 0.9218\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 0.0141 - accuracy: 0.9931 - val_loss: 0.5741 - val_accuracy: 0.9274\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.6158 - val_accuracy: 0.9218\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 0.6368 - val_accuracy: 0.9162\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0116 - accuracy: 0.9950 - val_loss: 0.6384 - val_accuracy: 0.9218\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0126 - accuracy: 0.9944 - val_loss: 0.7000 - val_accuracy: 0.9274\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0160 - accuracy: 0.9913 - val_loss: 0.6007 - val_accuracy: 0.9106\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.6004 - val_accuracy: 0.9162\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.5559 - val_accuracy: 0.9274\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0093 - accuracy: 0.9950 - val_loss: 0.5921 - val_accuracy: 0.9218\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0101 - accuracy: 0.9944 - val_loss: 0.5939 - val_accuracy: 0.9162\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0352 - accuracy: 0.9938 - val_loss: 0.5860 - val_accuracy: 0.9162\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5767 - val_accuracy: 0.9218\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0109 - accuracy: 0.9956 - val_loss: 0.5791 - val_accuracy: 0.9330\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0092 - accuracy: 0.9950 - val_loss: 0.6344 - val_accuracy: 0.9218\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0115 - accuracy: 0.9938 - val_loss: 0.6214 - val_accuracy: 0.9218\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0091 - accuracy: 0.9956 - val_loss: 0.6046 - val_accuracy: 0.9274\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0095 - accuracy: 0.9938 - val_loss: 0.6575 - val_accuracy: 0.9218\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.6483 - val_accuracy: 0.9162\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0123 - accuracy: 0.9938 - val_loss: 0.6861 - val_accuracy: 0.9162\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.6592 - val_accuracy: 0.9218\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0095 - accuracy: 0.9956 - val_loss: 0.6353 - val_accuracy: 0.9162\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0079 - accuracy: 0.9950 - val_loss: 0.6468 - val_accuracy: 0.9162\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.6840 - val_accuracy: 0.9162\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0110 - accuracy: 0.9938 - val_loss: 0.6266 - val_accuracy: 0.9162\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0086 - accuracy: 0.9950 - val_loss: 0.7502 - val_accuracy: 0.9162\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.6684 - val_accuracy: 0.9106\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.6945 - val_accuracy: 0.9106\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0076 - accuracy: 0.9950 - val_loss: 0.7572 - val_accuracy: 0.9162\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0338 - accuracy: 0.9956 - val_loss: 0.6751 - val_accuracy: 0.9218\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0096 - accuracy: 0.9956 - val_loss: 0.7616 - val_accuracy: 0.9106\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 0.7922 - val_accuracy: 0.9106\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0071 - accuracy: 0.9956 - val_loss: 0.7963 - val_accuracy: 0.9162\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 6s 365ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 0.7763 - val_accuracy: 0.9162\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.8177 - val_accuracy: 0.9162\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.7663 - val_accuracy: 0.9162\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0113 - accuracy: 0.9944 - val_loss: 0.9119 - val_accuracy: 0.9218\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 6s 341ms/step - loss: 0.0140 - accuracy: 0.9938 - val_loss: 0.7267 - val_accuracy: 0.9162\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 6s 358ms/step - loss: 0.0210 - accuracy: 0.9950 - val_loss: 0.8190 - val_accuracy: 0.9162\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.7519 - val_accuracy: 0.9162\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.7733 - val_accuracy: 0.9162\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0068 - accuracy: 0.9956 - val_loss: 0.7811 - val_accuracy: 0.9162\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0338 - accuracy: 0.9925 - val_loss: 0.7132 - val_accuracy: 0.9218\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0121 - accuracy: 0.9944 - val_loss: 0.7153 - val_accuracy: 0.9106\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.7830 - val_accuracy: 0.9106\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.7906 - val_accuracy: 0.9106\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0057 - accuracy: 0.9956 - val_loss: 0.7893 - val_accuracy: 0.9162\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0171 - accuracy: 0.9919 - val_loss: 0.7381 - val_accuracy: 0.9162\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0322 - accuracy: 0.9925 - val_loss: 0.7234 - val_accuracy: 0.9218\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.7228 - val_accuracy: 0.9218\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.7792 - val_accuracy: 0.9218\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0070 - accuracy: 0.9956 - val_loss: 0.7657 - val_accuracy: 0.9162\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 6s 357ms/step - loss: 0.0057 - accuracy: 0.9956 - val_loss: 0.7630 - val_accuracy: 0.9162\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 0.0061 - accuracy: 0.9963 - val_loss: 0.7499 - val_accuracy: 0.9162\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.7427 - val_accuracy: 0.9162\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.7173 - val_accuracy: 0.9162\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0081 - accuracy: 0.9956 - val_loss: 0.7262 - val_accuracy: 0.9106\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0060 - accuracy: 0.9963 - val_loss: 0.7594 - val_accuracy: 0.9162\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0093 - accuracy: 0.9938 - val_loss: 0.6974 - val_accuracy: 0.9218\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.6935 - val_accuracy: 0.9218\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.6974 - val_accuracy: 0.9330\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0082 - accuracy: 0.9956 - val_loss: 0.7264 - val_accuracy: 0.9162\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0064 - accuracy: 0.9969 - val_loss: 0.7049 - val_accuracy: 0.9218\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.7149 - val_accuracy: 0.9218\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.7593 - val_accuracy: 0.9274\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0077 - accuracy: 0.9956 - val_loss: 0.7366 - val_accuracy: 0.9330\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 0.7477 - val_accuracy: 0.9218\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0072 - accuracy: 0.9956 - val_loss: 0.7605 - val_accuracy: 0.9162\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0064 - accuracy: 0.9969 - val_loss: 0.7653 - val_accuracy: 0.9162\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0086 - accuracy: 0.9956 - val_loss: 0.7510 - val_accuracy: 0.9218\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0099 - accuracy: 0.9950 - val_loss: 0.7474 - val_accuracy: 0.9274\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0054 - accuracy: 0.9969 - val_loss: 0.7310 - val_accuracy: 0.9274\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0077 - accuracy: 0.9950 - val_loss: 0.7599 - val_accuracy: 0.9330\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0064 - accuracy: 0.9956 - val_loss: 0.7586 - val_accuracy: 0.9218\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0064 - accuracy: 0.9956 - val_loss: 0.7518 - val_accuracy: 0.9106\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0088 - accuracy: 0.9950 - val_loss: 0.8042 - val_accuracy: 0.9162\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0074 - accuracy: 0.9950 - val_loss: 0.7905 - val_accuracy: 0.9218\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0060 - accuracy: 0.9963 - val_loss: 0.8121 - val_accuracy: 0.9274\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0055 - accuracy: 0.9969 - val_loss: 0.8065 - val_accuracy: 0.9218\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0077 - accuracy: 0.9956 - val_loss: 0.7911 - val_accuracy: 0.9274\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0058 - accuracy: 0.9963 - val_loss: 0.8292 - val_accuracy: 0.9218\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0096 - accuracy: 0.9956 - val_loss: 0.9042 - val_accuracy: 0.9274\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0061 - accuracy: 0.9956 - val_loss: 0.8513 - val_accuracy: 0.9218\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 0.8536 - val_accuracy: 0.9162\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0059 - accuracy: 0.9969 - val_loss: 0.8641 - val_accuracy: 0.9218\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0055 - accuracy: 0.9963 - val_loss: 0.8752 - val_accuracy: 0.9162\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0326 - accuracy: 0.9956 - val_loss: 0.8671 - val_accuracy: 0.9218\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 0.8808 - val_accuracy: 0.9162\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0055 - accuracy: 0.9969 - val_loss: 0.8827 - val_accuracy: 0.9162\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0055 - accuracy: 0.9969 - val_loss: 0.9400 - val_accuracy: 0.9162\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0055 - accuracy: 0.9963 - val_loss: 0.9709 - val_accuracy: 0.9162\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0054 - accuracy: 0.9969 - val_loss: 0.9331 - val_accuracy: 0.9162\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 6s 339ms/step - loss: 0.0060 - accuracy: 0.9969 - val_loss: 0.9582 - val_accuracy: 0.9218\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.9397 - val_accuracy: 0.9162\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 0.9591 - val_accuracy: 0.9218\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0048 - accuracy: 0.9975 - val_loss: 0.9463 - val_accuracy: 0.9218\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 0.9019 - val_accuracy: 0.9218\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0052 - accuracy: 0.9963 - val_loss: 0.9337 - val_accuracy: 0.9218\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0090 - accuracy: 0.9956 - val_loss: 0.9335 - val_accuracy: 0.9218\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0075 - accuracy: 0.9950 - val_loss: 0.9970 - val_accuracy: 0.9162\n",
      "Epoch 291/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0052 - accuracy: 0.9975 - val_loss: 0.9848 - val_accuracy: 0.9106\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0053 - accuracy: 0.9969 - val_loss: 0.9696 - val_accuracy: 0.9106\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 0.9914 - val_accuracy: 0.9106\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0060 - accuracy: 0.9969 - val_loss: 0.9593 - val_accuracy: 0.9106\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0060 - accuracy: 0.9956 - val_loss: 1.0121 - val_accuracy: 0.9106\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0072 - accuracy: 0.9956 - val_loss: 0.9731 - val_accuracy: 0.9162\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 0.0054 - accuracy: 0.9956 - val_loss: 0.9985 - val_accuracy: 0.9162\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0052 - accuracy: 0.9963 - val_loss: 1.0045 - val_accuracy: 0.9162\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0053 - accuracy: 0.9963 - val_loss: 1.0340 - val_accuracy: 0.9162\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0047 - accuracy: 0.9975 - val_loss: 1.1064 - val_accuracy: 0.9218\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0100 - accuracy: 0.9950 - val_loss: 1.3055 - val_accuracy: 0.9162\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 1.1884 - val_accuracy: 0.9274\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 0.0106 - accuracy: 0.9956 - val_loss: 1.2800 - val_accuracy: 0.9162\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 1.1199 - val_accuracy: 0.9218\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 6s 359ms/step - loss: 0.0308 - accuracy: 0.9931 - val_loss: 1.0063 - val_accuracy: 0.9162\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0055 - accuracy: 0.9969 - val_loss: 1.0350 - val_accuracy: 0.9162\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0056 - accuracy: 0.9963 - val_loss: 1.0170 - val_accuracy: 0.9162\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0061 - accuracy: 0.9963 - val_loss: 1.0010 - val_accuracy: 0.9162\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0054 - accuracy: 0.9969 - val_loss: 1.0008 - val_accuracy: 0.9162\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0049 - accuracy: 0.9975 - val_loss: 0.9421 - val_accuracy: 0.9162\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0356 - accuracy: 0.9944 - val_loss: 0.9572 - val_accuracy: 0.9218\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 6s 342ms/step - loss: 0.0054 - accuracy: 0.9975 - val_loss: 1.0370 - val_accuracy: 0.9162\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0050 - accuracy: 0.9969 - val_loss: 1.0540 - val_accuracy: 0.9162\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 1.0854 - val_accuracy: 0.9162\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0071 - accuracy: 0.9956 - val_loss: 1.0197 - val_accuracy: 0.9106\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0053 - accuracy: 0.9975 - val_loss: 1.1290 - val_accuracy: 0.9162\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0059 - accuracy: 0.9956 - val_loss: 1.1370 - val_accuracy: 0.9162\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0079 - accuracy: 0.9956 - val_loss: 1.0508 - val_accuracy: 0.9218\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 1.0711 - val_accuracy: 0.9162\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0057 - accuracy: 0.9963 - val_loss: 1.1512 - val_accuracy: 0.9218\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 1.0664 - val_accuracy: 0.9218\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0053 - accuracy: 0.9956 - val_loss: 1.0731 - val_accuracy: 0.9162\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 1.0986 - val_accuracy: 0.9162\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 1.0996 - val_accuracy: 0.9162\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0276 - accuracy: 0.9963 - val_loss: 1.0852 - val_accuracy: 0.9218\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0061 - accuracy: 0.9956 - val_loss: 1.0396 - val_accuracy: 0.9162\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0048 - accuracy: 0.9963 - val_loss: 0.9839 - val_accuracy: 0.9162\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 1.0014 - val_accuracy: 0.9162\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0053 - accuracy: 0.9963 - val_loss: 0.9855 - val_accuracy: 0.9218\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0055 - accuracy: 0.9956 - val_loss: 1.0022 - val_accuracy: 0.9218\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0071 - accuracy: 0.9956 - val_loss: 1.0399 - val_accuracy: 0.9162\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0057 - accuracy: 0.9963 - val_loss: 1.0489 - val_accuracy: 0.9162\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0056 - accuracy: 0.9975 - val_loss: 1.0347 - val_accuracy: 0.9162\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0050 - accuracy: 0.9975 - val_loss: 1.0860 - val_accuracy: 0.9218\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 1.0823 - val_accuracy: 0.9162\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 1.0689 - val_accuracy: 0.9162\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0052 - accuracy: 0.9963 - val_loss: 1.0803 - val_accuracy: 0.9162\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0049 - accuracy: 0.9975 - val_loss: 1.1240 - val_accuracy: 0.9162\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0053 - accuracy: 0.9969 - val_loss: 1.0836 - val_accuracy: 0.9162\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0054 - accuracy: 0.9969 - val_loss: 1.1147 - val_accuracy: 0.9218\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0055 - accuracy: 0.9963 - val_loss: 1.0980 - val_accuracy: 0.9162\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 1.0983 - val_accuracy: 0.9218\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.3656 - val_accuracy: 0.9050\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0056 - accuracy: 0.9963 - val_loss: 1.1513 - val_accuracy: 0.9162\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0050 - accuracy: 0.9963 - val_loss: 1.1106 - val_accuracy: 0.9162\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0055 - accuracy: 0.9956 - val_loss: 1.0986 - val_accuracy: 0.9106\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.1205 - val_accuracy: 0.9162\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 1.0700 - val_accuracy: 0.9162\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 1.0808 - val_accuracy: 0.9162\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 1.0556 - val_accuracy: 0.9162\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0143 - accuracy: 0.9944 - val_loss: 1.1212 - val_accuracy: 0.9162\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0058 - accuracy: 0.9963 - val_loss: 1.0789 - val_accuracy: 0.9162\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0055 - accuracy: 0.9963 - val_loss: 1.1149 - val_accuracy: 0.9162\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.1015 - val_accuracy: 0.9162\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0100 - accuracy: 0.9956 - val_loss: 1.0967 - val_accuracy: 0.9162\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.1010 - val_accuracy: 0.9162\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.1624 - val_accuracy: 0.9162\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.1591 - val_accuracy: 0.9162\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 1.1320 - val_accuracy: 0.9162\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.1439 - val_accuracy: 0.9162\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.1483 - val_accuracy: 0.9162\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 1.1839 - val_accuracy: 0.9106\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 1.1883 - val_accuracy: 0.9162\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.2130 - val_accuracy: 0.9106\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 1.2168 - val_accuracy: 0.9106\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 1.2363 - val_accuracy: 0.9106\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 1.2242 - val_accuracy: 0.9106\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.2022 - val_accuracy: 0.9162\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 6s 342ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 1.1930 - val_accuracy: 0.9162\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0056 - accuracy: 0.9963 - val_loss: 1.1579 - val_accuracy: 0.9218\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0050 - accuracy: 0.9969 - val_loss: 1.1704 - val_accuracy: 0.9218\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.1831 - val_accuracy: 0.9106\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0057 - accuracy: 0.9963 - val_loss: 1.0953 - val_accuracy: 0.9218\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 6s 358ms/step - loss: 0.0059 - accuracy: 0.9950 - val_loss: 1.2019 - val_accuracy: 0.9162\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0055 - accuracy: 0.9963 - val_loss: 1.2674 - val_accuracy: 0.9106\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0060 - accuracy: 0.9963 - val_loss: 1.1378 - val_accuracy: 0.9162\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0052 - accuracy: 0.9963 - val_loss: 1.1192 - val_accuracy: 0.9162\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.1254 - val_accuracy: 0.9162\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0047 - accuracy: 0.9969 - val_loss: 1.1103 - val_accuracy: 0.9162\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0048 - accuracy: 0.9975 - val_loss: 1.0810 - val_accuracy: 0.9218\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0122 - accuracy: 0.9938 - val_loss: 1.0018 - val_accuracy: 0.9274\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0067 - accuracy: 0.9956 - val_loss: 1.0466 - val_accuracy: 0.9218\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 1.0532 - val_accuracy: 0.9274\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0050 - accuracy: 0.9963 - val_loss: 1.0580 - val_accuracy: 0.9330\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0046 - accuracy: 0.9975 - val_loss: 1.0612 - val_accuracy: 0.9330\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0046 - accuracy: 0.9975 - val_loss: 1.0558 - val_accuracy: 0.9162\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 1.1076 - val_accuracy: 0.9385\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0048 - accuracy: 0.9975 - val_loss: 1.1150 - val_accuracy: 0.9274\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0052 - accuracy: 0.9963 - val_loss: 1.0799 - val_accuracy: 0.9218\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 1.1102 - val_accuracy: 0.9330\n",
      "Epoch 391/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0055 - accuracy: 0.9969 - val_loss: 1.0921 - val_accuracy: 0.9274\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 1.4117 - val_accuracy: 0.9274\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0264 - accuracy: 0.9956 - val_loss: 1.3026 - val_accuracy: 0.9274\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0065 - accuracy: 0.9956 - val_loss: 1.0509 - val_accuracy: 0.9330\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0053 - accuracy: 0.9963 - val_loss: 1.0659 - val_accuracy: 0.9330\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 1.0529 - val_accuracy: 0.9330\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.0063 - accuracy: 0.9956 - val_loss: 0.9533 - val_accuracy: 0.9330\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0050 - accuracy: 0.9969 - val_loss: 0.9913 - val_accuracy: 0.9330\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0050 - accuracy: 0.9969 - val_loss: 1.0077 - val_accuracy: 0.9330\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0053 - accuracy: 0.9963 - val_loss: 1.0340 - val_accuracy: 0.9274\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.0797 - val_accuracy: 0.9274\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0432 - accuracy: 0.9931 - val_loss: 1.0764 - val_accuracy: 0.9218\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0074 - accuracy: 0.9956 - val_loss: 1.1162 - val_accuracy: 0.9106\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 1.0467 - val_accuracy: 0.9218\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.0489 - val_accuracy: 0.9218\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 1.0475 - val_accuracy: 0.9218\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0050 - accuracy: 0.9969 - val_loss: 1.1142 - val_accuracy: 0.9274\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0047 - accuracy: 0.9975 - val_loss: 1.0649 - val_accuracy: 0.9218\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0052 - accuracy: 0.9963 - val_loss: 1.1191 - val_accuracy: 0.9274\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0101 - accuracy: 0.9956 - val_loss: 1.1084 - val_accuracy: 0.9274\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.0809 - val_accuracy: 0.9274\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0049 - accuracy: 0.9963 - val_loss: 1.0721 - val_accuracy: 0.9218\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.0993 - val_accuracy: 0.9162\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0059 - accuracy: 0.9963 - val_loss: 1.1228 - val_accuracy: 0.9218\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0048 - accuracy: 0.9975 - val_loss: 1.1243 - val_accuracy: 0.9162\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0047 - accuracy: 0.9969 - val_loss: 1.1283 - val_accuracy: 0.9162\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.1352 - val_accuracy: 0.9162\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0047 - accuracy: 0.9969 - val_loss: 1.1039 - val_accuracy: 0.9162\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0044 - accuracy: 0.9975 - val_loss: 1.1127 - val_accuracy: 0.9106\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0048 - accuracy: 0.9975 - val_loss: 1.1003 - val_accuracy: 0.9162\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 1.1664 - val_accuracy: 0.9106\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 1.3358 - val_accuracy: 0.9162\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0065 - accuracy: 0.9969 - val_loss: 1.0812 - val_accuracy: 0.9162\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0047 - accuracy: 0.9969 - val_loss: 1.0732 - val_accuracy: 0.9162\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 1.0606 - val_accuracy: 0.9162\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0043 - accuracy: 0.9975 - val_loss: 1.0670 - val_accuracy: 0.9162\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0050 - accuracy: 0.9963 - val_loss: 1.0735 - val_accuracy: 0.9274\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0047 - accuracy: 0.9963 - val_loss: 1.1051 - val_accuracy: 0.9218\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0047 - accuracy: 0.9969 - val_loss: 1.1527 - val_accuracy: 0.9162\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0292 - accuracy: 0.9944 - val_loss: 1.0686 - val_accuracy: 0.9162\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 1.0685 - val_accuracy: 0.9162\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0050 - accuracy: 0.9963 - val_loss: 1.0384 - val_accuracy: 0.9274\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 1.0342 - val_accuracy: 0.9218\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.0385 - val_accuracy: 0.9162\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0048 - accuracy: 0.9975 - val_loss: 1.0429 - val_accuracy: 0.9162\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 6s 370ms/step - loss: 0.0052 - accuracy: 0.9963 - val_loss: 1.0446 - val_accuracy: 0.9218\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0048 - accuracy: 0.9956 - val_loss: 1.0455 - val_accuracy: 0.9218\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0055 - accuracy: 0.9956 - val_loss: 1.0802 - val_accuracy: 0.9218\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0045 - accuracy: 0.9975 - val_loss: 1.0534 - val_accuracy: 0.9218\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0052 - accuracy: 0.9975 - val_loss: 1.0904 - val_accuracy: 0.9218\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0050 - accuracy: 0.9963 - val_loss: 1.1125 - val_accuracy: 0.9274\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 1.1521 - val_accuracy: 0.9330\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.1332 - val_accuracy: 0.9274\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.1386 - val_accuracy: 0.9274\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 1.1540 - val_accuracy: 0.9218\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 6s 341ms/step - loss: 0.0047 - accuracy: 0.9956 - val_loss: 1.2912 - val_accuracy: 0.9218\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0096 - accuracy: 0.9950 - val_loss: 1.0070 - val_accuracy: 0.9274\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0053 - accuracy: 0.9969 - val_loss: 1.0805 - val_accuracy: 0.9218\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 1.1224 - val_accuracy: 0.9162\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 1.1889 - val_accuracy: 0.9162\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 1.2316 - val_accuracy: 0.9106\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0048 - accuracy: 0.9963 - val_loss: 1.1611 - val_accuracy: 0.9218\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 1.3708 - val_accuracy: 0.9274\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0047 - accuracy: 0.9969 - val_loss: 1.3158 - val_accuracy: 0.9274\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0045 - accuracy: 0.9963 - val_loss: 1.1292 - val_accuracy: 0.9218\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 1.1385 - val_accuracy: 0.9274\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 6s 356ms/step - loss: 0.0077 - accuracy: 0.9956 - val_loss: 1.1037 - val_accuracy: 0.9385\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 1.1249 - val_accuracy: 0.9274\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0047 - accuracy: 0.9969 - val_loss: 1.2262 - val_accuracy: 0.9330\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 6s 340ms/step - loss: 0.0055 - accuracy: 0.9950 - val_loss: 1.0958 - val_accuracy: 0.9330\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 1.0980 - val_accuracy: 0.9218\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.0991 - val_accuracy: 0.9218\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.0867 - val_accuracy: 0.9330\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.0995 - val_accuracy: 0.9274\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0055 - accuracy: 0.9963 - val_loss: 1.0971 - val_accuracy: 0.9218\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.1165 - val_accuracy: 0.9218\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.1264 - val_accuracy: 0.9218\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0051 - accuracy: 0.9963 - val_loss: 1.0682 - val_accuracy: 0.9441\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0054 - accuracy: 0.9963 - val_loss: 1.1235 - val_accuracy: 0.9274\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.1219 - val_accuracy: 0.9330\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 1.2860 - val_accuracy: 0.9385\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0349 - accuracy: 0.9944 - val_loss: 1.2834 - val_accuracy: 0.9274\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.1758 - val_accuracy: 0.9330\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.1313 - val_accuracy: 0.9330\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.1289 - val_accuracy: 0.9330\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0052 - accuracy: 0.9963 - val_loss: 1.0340 - val_accuracy: 0.9385\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.0229 - val_accuracy: 0.9274\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 6s 360ms/step - loss: 0.0066 - accuracy: 0.9956 - val_loss: 1.4548 - val_accuracy: 0.9385\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0173 - accuracy: 0.9963 - val_loss: 1.3111 - val_accuracy: 0.9274\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.3179 - val_accuracy: 0.9162\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 1.2475 - val_accuracy: 0.9274\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0050 - accuracy: 0.9963 - val_loss: 1.2824 - val_accuracy: 0.9274\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.3311 - val_accuracy: 0.9274\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.1853 - val_accuracy: 0.9274\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.2431 - val_accuracy: 0.9274\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.1981 - val_accuracy: 0.9274\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.1908 - val_accuracy: 0.9218\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.2283 - val_accuracy: 0.9274\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0048 - accuracy: 0.9969 - val_loss: 1.2365 - val_accuracy: 0.9218\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 1.2046 - val_accuracy: 0.9274\n",
      "Epoch 491/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0050 - accuracy: 0.9963 - val_loss: 1.2048 - val_accuracy: 0.9274\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.2303 - val_accuracy: 0.9218\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 6s 344ms/step - loss: 0.0045 - accuracy: 0.9963 - val_loss: 1.2380 - val_accuracy: 0.9218\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0045 - accuracy: 0.9969 - val_loss: 1.2481 - val_accuracy: 0.9162\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.0046 - accuracy: 0.9963 - val_loss: 1.2575 - val_accuracy: 0.9218\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.2596 - val_accuracy: 0.9218\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.0044 - accuracy: 0.9969 - val_loss: 1.2540 - val_accuracy: 0.9162\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.0046 - accuracy: 0.9969 - val_loss: 1.2540 - val_accuracy: 0.9162\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.0045 - accuracy: 0.9975 - val_loss: 1.2377 - val_accuracy: 0.9162\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.0042 - accuracy: 0.9975 - val_loss: 1.2206 - val_accuracy: 0.9162\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# This is already separating in trainign and validation\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 100 # group of outtuples as a batch\n",
    "\n",
    "history = model.fit(\n",
    "    X_traineval,\n",
    "    y_traineval,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          3200      \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                18816     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24129 (94.25 KB)\n",
      "Trainable params: 24129 (94.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/miniconda3/envs/slips/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_outputfile = f'../rnn_model_{model_trained}_2024-04-20.h5'\n",
    "model.summary()\n",
    "model.save(model_outputfile, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To plot the results of training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, \"ro\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
    "\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"rnn_model_{model_trained}-{model_train_date}.acc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"rnn_model_{model_trained}-{model_train_date}.loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 66ms/step - loss: 1.2258 - accuracy: 0.9305\n",
      "Test Generatilization Results:\n",
      "Test Loss: 1.2258477210998535\n",
      "Test Accuracy: 0.9304932951927185\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on the new dataset\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Test Generatilization Results:\")\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
